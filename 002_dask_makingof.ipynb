{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 17:21:34,062 [INFO] \n",
      "Limited Total Variation Regularization Support Detected! \n",
      "---> CVXPY is not installed. \n",
      "---> Many Total Variation Methods require CVXPY including: \n",
      "---> velocity, acceleration, jerk, jerk_sliding, smooth_acceleration\n",
      "---> Please install CVXPY to use these methods.\n",
      "---> Recommended to also install MOSEK and obtain a MOSEK license.\n",
      "You can still use: total_variation_regularization.iterative_velocity\n",
      "\n",
      "2023-05-26 17:21:34,064 [INFO] \n",
      "Limited Linear Model Support Detected! \n",
      "---> PYCHEBFUN is not installed. \n",
      "---> Install pychebfun to use chebfun derivatives (https://github.com/pychebfun/pychebfun/) \n",
      "You can still use other methods \n",
      "\n",
      "2023-05-26 17:21:34,064 [INFO] \n",
      "Limited Linear Model Support Detected! \n",
      "---> CVXPY is not installed. \n",
      "---> Install CVXPY to use lineardiff derivatives \n",
      "You can still use other methods \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Loading nx2pd.py version of 24.10.2022 @ 03:17PM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import dask.dataframe as dd\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Local imports\n",
    "#------------------------------------------------\n",
    "import WireDAQ.PandasPlus           # Make sure this import is after pandas\n",
    "import WireDAQ.Constants as cst\n",
    "import WireDAQ.NXCALS as nx\n",
    "import WireDAQ.Parser as parser\n",
    "import WireDAQ.Efficiency as eff\n",
    "\n",
    "main = __import__('000_Efficiency_per_fill')\n",
    "\n",
    "\n",
    "# Creating NXCALS variable containers\n",
    "#------------------------------------------------\n",
    "wires     = {'B1': [nx.NXCALSWire(loc = loc) for loc in ['L1B1','L5B1']],\n",
    "             'B2': [nx.NXCALSWire(loc = loc) for loc in ['R1B2','R5B2']]}\n",
    "beams     = [nx.NXCALSBeam(name) for name in ['B1','B2']]\n",
    "LHC       = nx.NXCALSLHC()\n",
    "b_slots   = np.arange(3564)\n",
    "#------------------------------------------------\n",
    "\n",
    "\n",
    "# Setting default values\n",
    "#------------------------------------------------\n",
    "_default_fig_width  = 2000\n",
    "_default_fig_height = 400\n",
    "\n",
    "_default_device = 'DBLM'\n",
    "\n",
    "_default_import = 'local'\n",
    "_default_path   = '/home/lumimod/work/run/data/2023/rawdata/'\n",
    "_default_out    = '/eos/user/p/phbelang/www/Monitoring_BBCW/'\n",
    "\n",
    "\n",
    "_default_path = '/home/phbelang/002mount'\n",
    "\n",
    "#------------------------------------------------\n",
    "\n",
    "# display(pd.DataFrame(gc.get_stats()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dask, computing efficiency\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import psutil\n",
    " \n",
    "# Getting % usage of virtual_memory ( 3rd field)\n",
    "print(40*'-' + '\\nBefore')\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "# Getting usage of virtual_memory in GB ( 4th field)\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "\n",
    "\n",
    "FILL        = 8773\n",
    "import_from = 'local'\n",
    "\n",
    "data_path= _default_path\n",
    "fill     = FILL\n",
    "dt       = 10\n",
    "baseline = None\n",
    "\n",
    "\n",
    "\n",
    "unix_s,unix_e = parser.fill_unix_times(fill,data_path=data_path)\n",
    "unix_bins     = np.arange(unix_s,unix_e,dt/1e-9)\n",
    "\n",
    "# STARTS HERE\n",
    "#=================================================\n",
    "\n",
    "def evaluate():\n",
    "    per_beam_list = []\n",
    "    for beam in beams:\n",
    "        # if beam.name == 'B1':\n",
    "        #     continue\n",
    "        \n",
    "        # Variables for this beam\n",
    "        variables = [beam['dBLM_Amp']['V'],\n",
    "                    beam['dBLM_Amp']['H-V-S']]\n",
    "        \n",
    "        # Iterate through bmode\n",
    "        per_mode_list = []\n",
    "        for bmode_path in Path(data_path + f'/HX:FILLN={fill}').glob(\"*\"):\n",
    "            # just for testing\n",
    "            # if 'STABLE' not in str(bmode_path):\n",
    "            #     continue\n",
    "\n",
    "            \n",
    "            _partition = dd.read_parquet(bmode_path,columns=variables)\n",
    "            _partition['unix'] = _partition.index\n",
    "            _partition = _partition.sort_values(by='unix')\n",
    "            _partition = _partition.set_index('unix')\n",
    "\n",
    "            _df = _partition.compute()\n",
    "        \n",
    "            per_type_list = []\n",
    "            for dblmType in ['V','H-V-S']:\n",
    "                observable = beam.dBLM_Amp[dblmType]\n",
    "                per_type_list.append(_df.bin_unix(observable,bins=unix_bins))\n",
    "\n",
    "            # Appending\n",
    "            per_mode_list.append(pd.concat(per_type_list,axis=1))\n",
    "\n",
    "            del(_partition)\n",
    "            del(_df)\n",
    "            gc.collect()\n",
    "\n",
    "        # Appending\n",
    "        per_beam_list.append(pd.concat(per_mode_list,axis=0))\n",
    "\n",
    "    #Appending\n",
    "    df = pd.concat(per_beam_list,axis=1)\n",
    "\n",
    "    # Adding proper timestamp\n",
    "    #============================================\n",
    "    df = df.sort_index()\n",
    "    df.index.name = 'unix'\n",
    "    df.insert(0,'Timestamp',df.index)\n",
    "    df.insert(1,'Time',1e-9*(df.index - df.index[0]))\n",
    "    df['Timestamp'] = df['Timestamp'].apply(lambda t: pd.Timestamp(t).tz_localize('UTC').tz_convert(cst.TZONE))\n",
    "    #============================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    display(pd.DataFrame(gc.get_stats()))\n",
    "\n",
    "\n",
    "    # Importing the library\n",
    "    import psutil\n",
    "    \n",
    "    # Getting % usage of virtual_memory ( 3rd field)\n",
    "    print(40*'-' + '\\nAfter')\n",
    "    print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "    # Getting usage of virtual_memory in GB ( 4th field)\n",
    "    print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "\n",
    "from memory_profiler import profile\n",
    "evaluate = profile(evaluate)\n",
    "evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data = df[beams[1]['dBLM_Amp']['V']].dropna().apply(lambda line:line[222])\n",
    "plt.plot(data.index,data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILL        = 8773\n",
    "import_from = 'local'\n",
    "\n",
    "data_path= _default_path\n",
    "fill     = FILL\n",
    "dt       = 10\n",
    "baseline = None\n",
    "\n",
    "variables = [beams[0]['dBLM_Amp']['V'],\n",
    "            beams[0]['dBLM_Amp']['H-V-S'],\n",
    "            beams[1]['dBLM_Amp']['V'],\n",
    "            beams[1]['dBLM_Amp']['H-V-S']]\n",
    "\n",
    "parser = parser.Memory_profiler()\n",
    "df = parser.load_and_bin(fill=FILL,variables = variables,dt = 10,beamMode = None,data_path= _default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILL        = 8773\n",
    "import_from = 'local'\n",
    "\n",
    "data_path= _default_path\n",
    "fill     = FILL\n",
    "dt       = 10\n",
    "baseline = None\n",
    "\n",
    "# variables = [beams[0]['dBLM_Amp']['V'],\n",
    "#             beams[0]['dBLM_Amp']['H-V-S'],\n",
    "#             beams[1]['dBLM_Amp']['V'],\n",
    "#             beams[1]['dBLM_Amp']['H-V-S']]\n",
    "\n",
    "parser = parser.Memory_profiler()\n",
    "df = parser.load_and_bin_sequential(fill=FILL,variables = None,dt = 10,beamMode = None,data_path= _default_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Before\n",
      "RAM memory % used: 31.2\n",
      "RAM Used (GB): 9.2929024\n",
      "Filename: /home/phbelang/abp/WireDAQ/WireDAQ/PandasPlus.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   113   6557.6 MiB   6557.6 MiB           1   @profile\n",
      "   114                                         def bin_unix(self,_var,bins=None,keeptype = True):\n",
      "   115                                             # GROUPING DATA IN TIME WINDOWS\n",
      "   116   6442.7 MiB   -114.9 MiB           1       sub     = self.dropna(subset=[_var])\n",
      "   117   5302.2 MiB  -1140.5 MiB           1       grouped = sub.groupby(pd.cut(sub.index,bins=bins))\n",
      "   118                                         \n",
      "   119                                             # AVG in each time window\n",
      "   120   5302.2 MiB      0.0 MiB           1       if keeptype:\n",
      "   121   5302.2 MiB      0.0 MiB           1           _type  = sub.iloc[0][_var].dtype\n",
      "   122   4658.6 MiB   -643.6 MiB       13169           values = grouped[_var].mean().apply(lambda line: line.astype(_type)).values\n",
      "   123                                             else:\n",
      "   124                                                 values = grouped[_var].mean().values\n",
      "   125                                         \n",
      "   126   4658.6 MiB      0.0 MiB           1       _type = sub.index.dtype\n",
      "   127   4663.2 MiB      4.6 MiB       13169       unix  = pd.Series(grouped.groups.keys()).apply(lambda line:line.mid.astype(_type)).values\n",
      "   128                                         \n",
      "   129   4663.2 MiB      0.0 MiB           1       return pd.DataFrame({_var:values},index=unix)\n",
      "\n",
      "\n",
      "Filename: /home/phbelang/abp/WireDAQ/WireDAQ/PandasPlus.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   113   4660.4 MiB   4660.4 MiB           1   @profile\n",
      "   114                                         def bin_unix(self,_var,bins=None,keeptype = True):\n",
      "   115                                             # GROUPING DATA IN TIME WINDOWS\n",
      "   116   4660.4 MiB      0.0 MiB           1       sub     = self.dropna(subset=[_var])\n",
      "   117   4660.4 MiB      0.0 MiB           1       grouped = sub.groupby(pd.cut(sub.index,bins=bins))\n",
      "   118                                         \n",
      "   119                                             # AVG in each time window\n",
      "   120   4660.4 MiB      0.0 MiB           1       if keeptype:\n",
      "   121   4660.4 MiB      0.0 MiB           1           _type  = sub.iloc[0][_var].dtype\n",
      "   122   4750.1 MiB     89.7 MiB       13169           values = grouped[_var].mean().apply(lambda line: line.astype(_type)).values\n",
      "   123                                             else:\n",
      "   124                                                 values = grouped[_var].mean().values\n",
      "   125                                         \n",
      "   126   4750.1 MiB      0.0 MiB           1       _type = sub.index.dtype\n",
      "   127   4753.7 MiB      3.6 MiB       13169       unix  = pd.Series(grouped.groups.keys()).apply(lambda line:line.mid.astype(_type)).values\n",
      "   128                                         \n",
      "   129   4753.7 MiB      0.0 MiB           1       return pd.DataFrame({_var:values},index=unix)\n",
      "\n",
      "\n",
      "Filename: /home/phbelang/abp/WireDAQ/WireDAQ/PandasPlus.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   113   4752.9 MiB   4752.9 MiB           1   @profile\n",
      "   114                                         def bin_unix(self,_var,bins=None,keeptype = True):\n",
      "   115                                             # GROUPING DATA IN TIME WINDOWS\n",
      "   116   4752.9 MiB      0.0 MiB           1       sub     = self.dropna(subset=[_var])\n",
      "   117   4752.9 MiB      0.0 MiB           1       grouped = sub.groupby(pd.cut(sub.index,bins=bins))\n",
      "   118                                         \n",
      "   119                                             # AVG in each time window\n",
      "   120   4752.9 MiB      0.0 MiB           1       if keeptype:\n",
      "   121   4752.9 MiB      0.0 MiB           1           _type  = sub.iloc[0][_var].dtype\n",
      "   122   4842.6 MiB     89.7 MiB       13169           values = grouped[_var].mean().apply(lambda line: line.astype(_type)).values\n",
      "   123                                             else:\n",
      "   124                                                 values = grouped[_var].mean().values\n",
      "   125                                         \n",
      "   126   4842.6 MiB      0.0 MiB           1       _type = sub.index.dtype\n",
      "   127   4844.2 MiB      1.5 MiB       13169       unix  = pd.Series(grouped.groups.keys()).apply(lambda line:line.mid.astype(_type)).values\n",
      "   128                                         \n",
      "   129   4844.2 MiB      0.0 MiB           1       return pd.DataFrame({_var:values},index=unix)\n",
      "\n",
      "\n",
      "Filename: /home/phbelang/abp/WireDAQ/WireDAQ/PandasPlus.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   113   4844.2 MiB   4844.2 MiB           1   @profile\n",
      "   114                                         def bin_unix(self,_var,bins=None,keeptype = True):\n",
      "   115                                             # GROUPING DATA IN TIME WINDOWS\n",
      "   116   4861.8 MiB     17.6 MiB           1       sub     = self.dropna(subset=[_var])\n",
      "   117   4861.8 MiB      0.0 MiB           1       grouped = sub.groupby(pd.cut(sub.index,bins=bins))\n",
      "   118                                         \n",
      "   119                                             # AVG in each time window\n",
      "   120   4861.8 MiB      0.0 MiB           1       if keeptype:\n",
      "   121   4861.8 MiB      0.0 MiB           1           _type  = sub.iloc[0][_var].dtype\n",
      "   122   4934.2 MiB     72.4 MiB       13169           values = grouped[_var].mean().apply(lambda line: line.astype(_type)).values\n",
      "   123                                             else:\n",
      "   124                                                 values = grouped[_var].mean().values\n",
      "   125                                         \n",
      "   126   4934.2 MiB      0.0 MiB           1       _type = sub.index.dtype\n",
      "   127   4934.7 MiB      0.5 MiB       13169       unix  = pd.Series(grouped.groups.keys()).apply(lambda line:line.mid.astype(_type)).values\n",
      "   128                                         \n",
      "   129   4934.7 MiB      0.0 MiB           1       return pd.DataFrame({_var:values},index=unix)\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "After\n",
      "RAM memory % used: 47.3\n",
      "RAM Used (GB): 14.221991936\n"
     ]
    }
   ],
   "source": [
    "# Importing the library\n",
    "import psutil\n",
    " \n",
    "# Getting % usage of virtual_memory ( 3rd field)\n",
    "print(40*'-' + '\\nBefore')\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "# Getting usage of virtual_memory in GB ( 4th field)\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)\n",
    "\n",
    "\n",
    "FILL        = 8773\n",
    "import_from = 'local'\n",
    "\n",
    "data_path= _default_path\n",
    "fill     = FILL\n",
    "dt       = 10\n",
    "baseline = None\n",
    "\n",
    "\n",
    "\n",
    "unix_s,unix_e = parser.fill_unix_times(fill,data_path=data_path)\n",
    "unix_bins     = np.arange(unix_s,unix_e,dt/1e-9)\n",
    "\n",
    "# STARTS HERE\n",
    "#=================================================\n",
    "\n",
    "variables = [beams[0]['dBLM_Amp']['V'],\n",
    "            beams[0]['dBLM_Amp']['H-V-S'],\n",
    "            beams[1]['dBLM_Amp']['V'],\n",
    "            beams[1]['dBLM_Amp']['H-V-S']]\n",
    "\n",
    "_partition = dd.read_parquet(data_path + f'/HX:FILLN={fill}',columns=variables)\n",
    "_df        = _partition.compute()\n",
    "_df        = _df.sort_index()\n",
    "\n",
    "del(_partition)\n",
    "gc.collect()\n",
    "\n",
    "per_type_list = []\n",
    "for col in _df.columns:\n",
    "\n",
    "    observable = col\n",
    "    per_type_list.append(_df.bin_unix(observable,bins=unix_bins))\n",
    "\n",
    "# Appending\n",
    "df = pd.concat(per_type_list,axis=1)\n",
    "# Adding proper timestamp\n",
    "#============================================\n",
    "df = df.sort_index()\n",
    "df.index.name = 'unix'\n",
    "df.insert(0,'Timestamp',df.index)\n",
    "df.insert(1,'Time',1e-9*(df.index - df.index[0]))\n",
    "df['Timestamp'] = df['Timestamp'].apply(lambda t: pd.Timestamp(t).tz_localize('UTC').tz_convert(cst.TZONE))\n",
    "#============================================\n",
    "\n",
    "# display(pd.DataFrame(gc.get_stats()))\n",
    "\n",
    "\n",
    "# Importing the library\n",
    "import psutil\n",
    " \n",
    "# Getting % usage of virtual_memory ( 3rd field)\n",
    "print(40*'-' + '\\nAfter')\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "# Getting usage of virtual_memory in GB ( 4th field)\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "After\n",
      "RAM memory % used: 47.1\n",
      "RAM Used (GB): 14.158155776\n"
     ]
    }
   ],
   "source": [
    "print(40*'-' + '\\nAfter')\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "# Getting usage of virtual_memory in GB ( 4th field)\n",
    "print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect(generation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect(generation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_partition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _partition\n",
      "\u001b[0;31mNameError\u001b[0m: name '_partition' is not defined"
     ]
    }
   ],
   "source": [
    "_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index                                                    0.052672\n",
       " Timestamp                                                0.052672\n",
       " Time                                                     0.052672\n",
       " HC.TZ76.BLMDIAMOND2.3:AcquisitionIntegral:intSumBuf1    94.651584\n",
       " HC.TZ76.BLMDIAMOND3.3:AcquisitionIntegral:intSumBuf1    94.651584\n",
       " HC.TZ76.BLMDIAMOND2.5:AcquisitionIntegral:intSumBuf1    94.651584\n",
       " HC.TZ76.BLMDIAMOND3.5:AcquisitionIntegral:intSumBuf1    94.651584\n",
       " dtype: float64,\n",
       " Index                                                   18.547384\n",
       " HC.TZ76.BLMDIAMOND2.3:AcquisitionIntegral:intSumBuf1    61.962120\n",
       " HC.TZ76.BLMDIAMOND3.3:AcquisitionIntegral:intSumBuf1    61.962216\n",
       " HC.TZ76.BLMDIAMOND2.5:AcquisitionIntegral:intSumBuf1    61.962024\n",
       " HC.TZ76.BLMDIAMOND3.5:AcquisitionIntegral:intSumBuf1    61.962120\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True)/1e6,_df.memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                                                   18.547384\n",
       "HC.TZ76.BLMDIAMOND2.3:AcquisitionIntegral:intSumBuf1    61.962120\n",
       "HC.TZ76.BLMDIAMOND3.3:AcquisitionIntegral:intSumBuf1    61.962216\n",
       "HC.TZ76.BLMDIAMOND2.5:AcquisitionIntegral:intSumBuf1    61.962024\n",
       "HC.TZ76.BLMDIAMOND3.5:AcquisitionIntegral:intSumBuf1    61.962120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================\n",
    "_df = _df.sort_index()\n",
    "_df.index.name = 'unix'\n",
    "_df.insert(0,'Timestamp',_df.index)\n",
    "_df.insert(1,'Time',1e-9*(_df.index - _df.index[0]))\n",
    "_df['Timestamp'] = _df['Timestamp'].apply(lambda t: pd.Timestamp(t).tz_localize('UTC').tz_convert(cst.TZONE))\n",
    "#============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.set_index('Time')[variables[0]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Time')[variables[1]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.set_index('Time')[variables[1]].dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing binning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unix_s,unix_e = parser.fill_unix_times(fill,data_path=data_path)\n",
    "unix_bins     = np.arange(unix_s,unix_e,dt/1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=unix_bins\n",
    "_var=variables[0]\n",
    "# GROUPING DATA IN TIME WINDOWS\n",
    "sub     = _df.dropna(subset=[_var])\n",
    "grouped = sub.groupby(pd.cut(sub.index,bins=bins))\n",
    "\n",
    "# AVG in each time window\n",
    "values   = np.array(grouped[_var].mean())\n",
    "unix     = np.array(pd.Series(grouped.groups.keys()).apply(lambda line:line.mid))\n",
    "\n",
    "pd.DataFrame({_var:values},index=unix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grouped.groups.keys()).apply(lambda line:line.mid).values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = sub.iloc[0][_var].dtype\n",
    "grouped[_var].mean().apply(lambda line: line.astype(_type)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(sub.index.astype('float32').values[0])/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.index.astype('int64').values[0]/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = sub.index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = sub.index.dtype\n",
    "pd.Series(grouped.groups.keys()).apply(lambda line:line.mid.astype(_type)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grouped.groups.keys()).apply(lambda line:line.mid).values[0]/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(grouped[_var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.index[0]/1*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(df[variables[0]].dropna().iloc[:i].memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "sample1 = df[variables[0]].dropna().iloc[:i]\n",
    "sample2 = _df[variables[0]].dropna().iloc[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "display(pd.DataFrame({'data':sample1.values}).memory_usage(deep=True)/1e6)\n",
    "\n",
    "gc.collect()\n",
    "display(pd.DataFrame({'data':sample2.values}).memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables[0]].memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().iloc[0].nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "display(pd.DataFrame({'data':sample1.values.copy()}).memory_usage(deep=True)/1e6)\n",
    "\n",
    "gc.collect()\n",
    "display(pd.DataFrame({'data':sample2.values.copy()}).memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.Series(sample1.values.tolist()).memory_usage(deep=True)/1e6)\n",
    "display(pd.Series(sample2.values.tolist()).memory_usage(deep=True)/1e6)\n",
    "display(pd.Series(sample3.copy(deep=True)).memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.dropna(subset=[variables[0]]).iloc[0].nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample1.apply(lambda line: line.astype('int32')).memory_usage(deep=True)/1e6)\n",
    "display(sample2.apply(lambda line: line.astype('int32')).memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2.values.tolist(),sample1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sample2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2.apply(lambda line: [type(i) for i in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sample1.apply(lambda line: [type(i) if not isinstance(i,np.int32) else 0  for i in line]).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sample2.apply(lambda line: [type(i) if not isinstance(i,np.int32) else 0  for i in line]).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(sample1.values[0][0],np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2.values[0].nbytes/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'data':sample1.values}).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1.values[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample1.values[0]),type(sample2.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sample1.values[0]/1e6,sample2.values[0]/1e6,'o')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1,sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(_df[variables[0]].dropna().iloc[:i].memory_usage(deep=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().iloc[:1].memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df[variables[0]].dropna().iloc[:1].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df[variables[0]].dropna().iloc[:1].values[0],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(_df[variables[0]].dropna().iloc[:1].values[0],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(_df[variables[0]].dropna().iloc[:1].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().iloc[:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables[0]].dropna().iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:100].index.values.dtype,_df.iloc[:100].index.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.iloc[:100].index.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([_df.index[0]],dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([_df.index[0]],dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(grouped.groups.keys()).apply(lambda line:line.mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(grouped[_var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[_var].mean().index.apply(lambda line:line.mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[_var].mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(df)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(_df)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(df[variables[0]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(_df[variables[0]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables[0]].dropna().memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables[0]].memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].memory_usage(deep=True)/1e6,df[variables[0]].memory_usage(deep=True)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna().iloc[0].dtype,df[variables[0]].iloc[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,3],dtype='int32').dtype,pd.Series([1,2,3],dtype='float64').dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Data':[1,2,3,4,5,6,7,8]},dtype='int32').memory_usage(deep=True),pd.DataFrame({'Data':[1,2,3,4,5,6,7,8]},dtype='float64').memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Data':[1,2,3,4,5,6,7,8]},dtype='int32').memory_usage(deep=True),pd.DataFrame({'Data':[1,2,3,4,5,6,7,8]},dtype='float64').memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[variables[0]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[variables[0]].dropna().iloc[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_df[variables[0]].dropna().iloc[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.rename(columns={beam.dBLM_Amp['V']:f'DBLM.{beam.name}.V'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(gc.get_stats()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_partition.compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unix_e-unix_s)*1e-9/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(gc.get_stats()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHC.Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dd.read_parquet(data_path + f'/HX:FILLN={fill}',columns=[LHC.Fill]).compute()\n",
    "test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bmode_path in Path(data_path + f'/HX:FILLN={fill}').glob(\"*\"):\n",
    "    if 'STABLE' in str(bmode_path):\n",
    "        print(bmode_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmode_path.contains('FIL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_wireDAQ",
   "language": "python",
   "name": "py_wiredaq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "551bc2e2e6b6c9fefe45aa7539a662d5bda46fb26d0014793dfd45eb97522430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
